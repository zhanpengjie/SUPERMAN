{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157989\n",
      "19749\n",
      "19749\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/combined_data_sorted.csv')\n",
    "# This converts the actual page number to its label importance\n",
    "df['page'] = 50 - df['page']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state = 0)\n",
    "df_test, df_valid = train_test_split(df_test, test_size = 0.5, random_state = 0)\n",
    "\n",
    "print(len(df_train.index))\n",
    "print(len(df_test.index))\n",
    "print(len(df_valid.index))\n",
    "\n",
    "df_train = df_train.sort_values(by = ['qid', 'page'], ascending = [True, False])\n",
    "df_test = df_test.sort_values(by = ['qid', 'page'], ascending = [True, False])\n",
    "df_valid = df_valid.sort_values(by = ['qid', 'page'], ascending = [True, False])\n",
    "\n",
    "# df_train.to_csv('data/train.csv', index = False)\n",
    "# df_test.to_csv('data/test.csv', index = False)\n",
    "# df_valid.to_csv('data/valid.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:21:23] 157989x15 matrix with 2211846 entries loaded from data/train.txt\n",
      "[16:21:24] 19749x15 matrix with 276486 entries loaded from data/test.txt\n",
      "[16:21:24] 19749x15 matrix with 276486 entries loaded from data/valid.txt\n",
      "[0]\ttrain-ndcg:0.985411\teval-ndcg:1.00324\n",
      "[1]\ttrain-ndcg:0.984895\teval-ndcg:0.997044\n",
      "[2]\ttrain-ndcg:0.984488\teval-ndcg:0.996048\n",
      "[3]\ttrain-ndcg:0.984629\teval-ndcg:0.994509\n",
      "[4]\ttrain-ndcg:0.985558\teval-ndcg:0.995685\n",
      "[5]\ttrain-ndcg:0.985012\teval-ndcg:0.996697\n",
      "[6]\ttrain-ndcg:0.985374\teval-ndcg:0.992829\n",
      "[7]\ttrain-ndcg:0.986042\teval-ndcg:0.992206\n",
      "[8]\ttrain-ndcg:0.986485\teval-ndcg:0.99134\n",
      "[9]\ttrain-ndcg:0.985809\teval-ndcg:0.992673\n",
      "[ 0.39328828  0.2774906   0.50972015 ... -0.14677787 -0.16700876\n",
      " -0.16700876]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix('data/train.txt')\n",
    "dtrain_group = pd.read_csv('data/train.csv').groupby(['qid']).size().values\n",
    "dtrain.set_group(dtrain_group)\n",
    "\n",
    "dtest  = xgb.DMatrix('data/test.txt')\n",
    "dtest_group = pd.read_csv('data/test.csv').groupby(['qid']).size().values\n",
    "dtest.set_group(dtest_group)\n",
    "\n",
    "dvalid = xgb.DMatrix('data/valid.txt')\n",
    "dvalid_group = pd.read_csv('data/valid.csv').groupby(['qid']).size().values\n",
    "dvalid.set_group(dvalid_group)\n",
    "\n",
    "params = {\n",
    "    'objective': 'rank:pairwise',\n",
    "    'eval_metric': 'ndcg',\n",
    "    'max_depth': 10\n",
    "}\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_boost_round = 10, evals = [(dtrain, 'train'), (dvalid, 'eval')])\n",
    "print(bst.predict(dtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'titleScore': 418,\n",
       " 'price': 2420,\n",
       " 'salesCount': 1085,\n",
       " 'goodComment': 1239,\n",
       " 'badComment': 170,\n",
       " 'picComment': 617,\n",
       " 'categoryId': 236,\n",
       " 'downTime': 0,\n",
       " 'freeDelivery': 214,\n",
       " 'isNewProduct': 30,\n",
       " 'commonweal': 0,\n",
       " 'taojinbi': 143,\n",
       " 'shopCreditScore': 1193,\n",
       " 'shopServiceScore': 388}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "columns = pd.read_csv('data/train.csv').columns[1:-1]\n",
    "feature_importance = {\n",
    "    columns[0]: bst.get_fscore()['f1'],\n",
    "    columns[1]: bst.get_fscore()['f2'],\n",
    "    columns[2]: bst.get_fscore()['f3'],\n",
    "    columns[3]: bst.get_fscore()['f4'],\n",
    "    columns[4]: bst.get_fscore()['f5'],\n",
    "    columns[5]: bst.get_fscore()['f6'],\n",
    "    columns[6]: bst.get_fscore()['f7'],\n",
    "    columns[7]: 0,\n",
    "    columns[8]: bst.get_fscore()['f9'],\n",
    "    columns[9]: bst.get_fscore()['f10'],\n",
    "    columns[10]: 0,\n",
    "    columns[11]: bst.get_fscore()['f12'],\n",
    "    columns[12]: bst.get_fscore()['f13'],\n",
    "    columns[13]: bst.get_fscore()['f14']\n",
    "}\n",
    "print(\"Feature Importance:\")\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
