{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import io\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image\n",
    "from numpy import genfromtxt\n",
    "from six import StringIO\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "import gensim\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import pydotplus\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['font.serif'] = ['SimHei']\n",
    "sns.set_style(\"darkgrid\",{\"font.sans-serif\":['simhei', 'Arial']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all available file names\n",
    "folder = \"data/standardized_data\"\n",
    "files = glob.glob(f\"{folder}/*\")\n",
    "file_with_over_800_lines = []\n",
    "for f in files:\n",
    "    filename = os.path.basename(f)\n",
    "    num_lines = sum(1 for line in open(f))\n",
    "    if num_lines > 800:\n",
    "        file_with_over_800_lines.append(filename)\n",
    "\n",
    "# print(file_with_over_800_lines)\n",
    "# remove some of inappropriate query words\n",
    "file_with_over_800_lines.remove('28_2019-05-23_rank_美妆_value.csv')\n",
    "file_with_over_800_lines.remove('1_2019-05-23_rank_刀片_value.csv')\n",
    "file_with_over_800_lines.remove('10_2019-05-23_rank_指甲剪套装_value.csv')\n",
    "file_with_over_800_lines.remove('34_2019-05-23_rank_工具_value.csv')\n",
    "file_with_over_800_lines.remove('33_2019-05-23_rank_美妆工具_value.csv')\n",
    "file_with_over_800_lines.remove('18_2019-05-23_rank_化妆品_value.csv')\n",
    "file_with_over_800_lines.remove('27_2019-05-23_rank_彩妆_value.csv')\n",
    "file_with_over_800_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ['accuracy', 'precision', 'recall']\n",
    "headers = [\n",
    "    '价格数值', \n",
    "    '销量数值', \n",
    "    '好评数值', \n",
    "    '差评数值', \n",
    "    '有图评论数值',\n",
    "    '类目ID数值',\n",
    "    '下架时间数值',\n",
    "    '免运费数值',\n",
    "    '新品数值',\n",
    "    '公益宝贝数值',\n",
    "    '淘金币数值',\n",
    "    '信誉等级数值',\n",
    "    '店铺服务数值'\n",
    "]\n",
    "cols = ['关键词'] + results + headers\n",
    "results = []\n",
    "\n",
    "def normalize_columns_except(df, column):\n",
    "    columns = list(df.columns)\n",
    "    columns.remove('qid')\n",
    "    columns.remove(column)\n",
    "    \n",
    "    mean = df.mean()\n",
    "    copy = df.copy()\n",
    "    for col in columns:\n",
    "        copy[col] = mean[col]\n",
    "        \n",
    "    return copy\n",
    "\n",
    "def row_prediction(y, column, new_value):\n",
    "    y[0][X.columns.get_loc(column)] = new_value\n",
    "    return model.predict(y)\n",
    "\n",
    "def binary_search_turning_point(lo, hi, column):\n",
    "    if hi - lo > 0.000001:\n",
    "        lo_pred = row_prediction(y, column, lo)\n",
    "        hi_pred = row_prediction(y, column, hi)\n",
    "        \n",
    "        mi = (lo + hi) / 2\n",
    "        mi_pred = row_prediction(y, column, mi)\n",
    "        \n",
    "        if lo_pred == mi_pred:\n",
    "            return binary_search_turning_point(mi, hi, column)\n",
    "        else:\n",
    "            return binary_search_turning_point(lo, mi, column)\n",
    "    else:\n",
    "        return lo\n",
    "\n",
    "for filename in file_with_over_800_lines:\n",
    "    file = f\"{folder}/{filename}\"\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "    model = DecisionTreeClassifier(criterion = 'gini', random_state = 100)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    row = []\n",
    "    row.append(filename)\n",
    "    row.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    row.append(metrics.precision_score(y_test, y_pred))\n",
    "    row.append(metrics.recall_score(y_test, y_pred))\n",
    "    \n",
    "    for col in headers:\n",
    "        y = X.mean().values.reshape((1, -1))\n",
    "        row.append(binary_search_turning_point(0, 1, col))\n",
    "    \n",
    "    results.append(row)\n",
    "    \n",
    "result = pd.DataFrame(results, columns = cols)\n",
    "result.to_csv('single_query_turning_point_analysis.csv', index = False, encoding='utf-8-sig')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relationship between query and feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"data/standardized_data\"\n",
    "queries = []\n",
    "columns = ['qid', '商品名称数值'] + headers + ['排行数值']\n",
    "for filename in file_with_over_800_lines:\n",
    "    file = f\"{folder}/{filename}\"\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    corr = df.corr()\n",
    "    queries.append(corr.iloc[-1, :].values)\n",
    "\n",
    "file = \"data/aggregated_data/combined_data.csv\"\n",
    "    \n",
    "df = pd.read_csv(file)\n",
    "queries.append(df.corr().iloc[-1, :].values)\n",
    "\n",
    "index = file_with_over_800_lines + ['combined_data.csv']\n",
    "df = pd.DataFrame(queries, index = index, columns = columns)\n",
    "df = df.iloc[:, 1:-1]\n",
    "colormap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "#Generate Heat Map, allow annotations and place floats in map\n",
    "sns.heatmap(df, cmap=colormap, annot=True, fmt=\".2f\")\n",
    "#Apply xticks\n",
    "plt.xticks(range(len(columns[1:-1])), columns[1:-1]);\n",
    "#Apply yticks\n",
    "plt.yticks(range(len(index)), index)\n",
    "#show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
